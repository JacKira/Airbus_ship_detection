{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRIxdbvBMmE3"
   },
   "source": [
    "## Параметыр модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meFFnC2AVHdp"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EDGE_CROP = 16\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = \"SIMPLE\"\n",
    "\n",
    "#Понижение дискритизации внутри сети\n",
    "NET_SCALING = (1, 1)\n",
    "\n",
    "#Понижение размерности в предобработке\n",
    "IMG_SCALING = (3, 3)\n",
    "\n",
    "#Число изображений для валидации\n",
    "VALID_IMG_COUNT = 900\n",
    "\n",
    "#Максимальное число шагов за эпоху при обучении\n",
    "MAX_TRAIN_STEPS = 9\n",
    "MAX_TRAIN_EPOCHS = 50\n",
    "AUGMENT_BRIGHTNESS = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgCdn1_lfMl3"
   },
   "outputs": [],
   "source": [
    "from skimage.util import montage\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "import gc; gc.enable()\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKORYddprw3l"
   },
   "outputs": [],
   "source": [
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = \"/content/drive/MyDrive/Диплом/Ship_detection/Input/\"\n",
    "train_image_dir = os.path.join(ship_dir, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0RQsHC7MvVQ"
   },
   "source": [
    "## Определим вспомогательные процедуры для декодирования, кодирования и вывода изображения и маски корабля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nOB1-xKn9RD"
   },
   "outputs": [],
   "source": [
    "def rle_encode(img, min_max_treshold = 1e-3, max_mean_treshold = None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Возвращает бегущую строку как форматированную\n",
    "    '''\n",
    "    if (np.max(img) < min_max_treshold):\n",
    "        return ''\n",
    "    if (max_mean_treshold and np.mean(img) > max_mean_treshold):\n",
    "        return ''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWdYQ8mNijUS"
   },
   "outputs": [],
   "source": [
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Кодируем объединенные регионы как разделители масок\n",
    "    '''\n",
    "    labels = label(img)\n",
    "    if img.ndim > 2:\n",
    "      return [rle_encode(np.sum(labels == k, axis = 2), **kwargs) for k in np.unique(labels[labels > 0])]\n",
    "    else:\n",
    "        return [rle_encode(labels == k, **kwargs) for k in np.unique(labels[labels > 0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVzSVuwxnn0F"
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape = (768, 768)):\n",
    "    '''\n",
    "    mask_rle: бегущая - длина как форматированная строка (start length)\n",
    "    shape: (height,width) массив для возвратного значения \n",
    "    Возвращаем  numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype = int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype = np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEzxc5LlqrLT"
   },
   "outputs": [],
   "source": [
    "def masks_as_image(in_mask_list):\n",
    "    #Берем индивидуальную маску корабля и создаем отдельный массив масок для всех кораблей\n",
    "    all_masks = np.zeros((768, 768), dtype = np.uint8)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks |= rle_decode(mask)\n",
    "    return all_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsfRRYNCrOir"
   },
   "outputs": [],
   "source": [
    "def masks_as_color(in_mask_list):\n",
    "    #Берем индивидуальную маску корабля и создаем цветовую маску для каждого корабля\n",
    "    all_masks = np.zeros((768, 768), dtype = np.float)\n",
    "    scale = lambda x: (len(in_mask_list) + x + 1) / (len(in_mask_list) * 2)\n",
    "    for i, mask in enumerate(in_mask_list):\n",
    "        if isinstance(mask, str):\n",
    "            all_masks[:, :] += scale(i) * rle_decode(mask)\n",
    "    return all_masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sKpBxvfM-dD"
   },
   "source": [
    "## Продемонстрируем работу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Arxk5TyPtbB3",
    "outputId": "ed797e1c-6ca3-4fc6-c4ba-8dd96cd700c9"
   },
   "outputs": [],
   "source": [
    "masks = pd.read_csv(\"/content/drive/MyDrive/Диплом/Ship_detection/Input/ImgForTest.csv\")\n",
    "masks = masks.drop(['Unnamed: 0', 'exist_ship'], axis=1)\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxpil4MNuTMF",
    "outputId": "1a4706ca-546b-49af-bd80-538430995cbb"
   },
   "outputs": [],
   "source": [
    "not_empty = pd.notna(masks.EncodedPixels)\n",
    "print(not_empty.sum(), \"masks in\", masks[not_empty].ImageId.nunique(), 'Images')\n",
    "print((~not_empty).sum(), \"empty images in\", masks.ImageId.nunique(), \"total images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "QsJTQikq1wJS",
    "outputId": "bc1ee188-0f9e-4768-a917-bf8c3a3586a1"
   },
   "outputs": [],
   "source": [
    "im = Image.open(\"/content/drive/MyDrive/Диплом/Ship_detection/Input/train/8ce7d933f.jpg\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "PwGcm9y8vVuc",
    "outputId": "a0d1cbd0-0a43-4efe-84dd-03f0557640fc"
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(1, 5, figsize = (30, 5))\n",
    "rle_0 = masks.query('ImageId == \"8ce7d933f.jpg\"')[\"EncodedPixels\"]\n",
    "img_0 = masks_as_image(rle_0)\n",
    "ax0.imshow(im)\n",
    "ax0.set_title(\"Оригинальное изображение\")\n",
    "\n",
    "ax1.imshow(img_0)\n",
    "ax1.set_title(\"Маска как изображение\")\n",
    "\n",
    "rle_1 = multi_rle_encode(img_0)\n",
    "img_1 = masks_as_color(rle_0)\n",
    "ax2.imshow(img_1)\n",
    "ax2.set_title(\"Перекодированное\")\n",
    "\n",
    "img_c = masks_as_color(rle_0)\n",
    "ax3.imshow(img_c)\n",
    "ax3.set_title(\"Масква в цвете\")\n",
    "\n",
    "img_c = masks_as_color(rle_1)\n",
    "ax4.imshow(img_c)\n",
    "ax4.set_title(\"Перекодированное в цвета\")\n",
    "print(\"Проверка Декодирования -> Кодирование\", 'RLE_0:', len(rle_0), '->',\n",
    "      'RLE_1:', len(rle_1))\n",
    "print(np.sum(img_0 - img_1), 'error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoiyQwyyNJKD"
   },
   "source": [
    "<h1> Разделим данные на тренировочные и проверочные</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "jrY4fFuSxDlS",
    "outputId": "04d23578-95c0-4b97-98f6-792147c6539f"
   },
   "outputs": [],
   "source": [
    "#Поле, указывающее, есть ли корабль на картинке:  1 - есть, 0 - нет\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)    \n",
    "unique_img_ids = masks.groupby(\"ImageId\").agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x > 0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: os.stat(os.path.join(train_image_dir, c_img_id)).st_size/1024)\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis = 1, inplace = True)\n",
    "unique_img_ids.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aypgOV2cPvS8"
   },
   "source": [
    "## Построим гистограмму от числа кораблей (копий изображения) для одного файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "b4r6E50LPiVL",
    "outputId": "95491c63-aa85-49a3-df6d-12ad9d698f33"
   },
   "outputs": [],
   "source": [
    "unique_img_ids['ships'].hist(bins= unique_img_ids['ships'].max() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSFPaDcKQ4ev"
   },
   "source": [
    "======================== МЕСТО ДЛЯ ОТСЕИВАНИЯ ДУБЛИКАТОВ ==========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BngSy_HYRN_A"
   },
   "source": [
    "## Сбалансируем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iyOScioSNqw",
    "outputId": "d04195ae-a373-4027-9007-42239b747fe9"
   },
   "outputs": [],
   "source": [
    "train_ids, valid_ids = train_test_split(unique_img_ids, test_size = 0.25, random_state = SEED)\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gebUHPI-Twa_"
   },
   "source": [
    "## Декодируем данные в изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhfBRxanT8_G"
   },
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = np.expand_dims(masks_as_image(c_masks['EncodedPixels'].values), -1)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "rDNIfhr4T-8M",
    "outputId": "18c2d53c-285d-4f5e-d414-6248015b36ea"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x (2048, 256, 256, 3) 0.0 1.0\n",
    "y (2048, 256, 256, 1) 0 1\n",
    "\n",
    "train_gen = make_image_gen(train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "HL-etUwvUBpi",
    "outputId": "9f1011c4-f578-4a77-8f8a-d82b657f735b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                           batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')\n",
    "fig.savefig('overview.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t51NVgTMXdG_"
   },
   "source": [
    "## Сделаем набор для проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpgZVrT1UNrz",
    "outputId": "a0373886-0317-457a-c36e-0fdb989718ab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFsvux9Gd7C9",
    "outputId": "ebbf8ae6-482f-40db-9b3f-3d0d3b443c24"
   },
   "outputs": [],
   "source": [
    "valid_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yh1O033Bd87U",
    "outputId": "e26519b8-7fa0-4052-c3fd-e2a537dade0e"
   },
   "outputs": [],
   "source": [
    "s = 10\n",
    "j = 0\n",
    "for r in valid_y[-17]:\n",
    "    k = 10\n",
    "    i = 0\n",
    "    for c in r:\n",
    "        if(i > k):\n",
    "            print(\"...\")\n",
    "            break;\n",
    "        print(c, sep=' ', end='', flush=True)\n",
    "        i += 1\n",
    "    print\n",
    "    j += 1\n",
    "    if(j > k):\n",
    "            print(\"...\")\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UFaGyCAXzul"
   },
   "source": [
    "##Дополним данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFiuxnwdXtvR"
   },
   "outputs": [],
   "source": [
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "16ImDGZnkiTW",
    "outputId": "2277dced-5678-4d7a-f2b7-0d2a3706384f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x (64, 256, 256, 3) float32 0.0 1.0\n",
    "y (64, 256, 256, 1) float32 0.0 1.0\n",
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 9 samples to examine in detail\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OmyMFhLkvaI",
    "outputId": "d3c64663-506d-4e22-ae63-bac4cb707079"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoprUMwmk5cK"
   },
   "source": [
    "## Соберем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUz2fnchk2LQ",
    "outputId": "a79c1fe4-4bc8-4fc7-cbf0-defaf449e2ae"
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return layers.UpSampling2D(strides)\n",
    "\n",
    "if UPSAMPLE_MODE=='DECONV':\n",
    "    upsample=upsample_conv\n",
    "else:\n",
    "    upsample=upsample_simple\n",
    "    \n",
    "input_img = layers.Input([256, 256, 3], name = 'RGB_Input')\n",
    "pp_in_layer = input_img\n",
    "\n",
    "if NET_SCALING is not None:\n",
    "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
    "    \n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = layers.MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = layers.MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = layers.MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = layers.concatenate([u6, c4])\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = layers.concatenate([u7, c3])\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = layers.concatenate([u8, c2])\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = layers.concatenate([u9, c1], axis=3)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "# d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "# d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "if NET_SCALING is not None:\n",
    "    d = layers.UpSampling2D(NET_SCALING)(d)\n",
    "\n",
    "seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cU1RvevYzv8g",
    "outputId": "c22fabe4-997a-438f-82c0-0a9b3b06af58"
   },
   "outputs": [],
   "source": [
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(seg_model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C31X67g-6TTJ"
   },
   "outputs": [],
   "source": [
    "#https://lars76.github.io/2018/09/27/loss-functions-for-segmentation.html\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return numerator / denominator\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "  return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "\n",
    "#Cross entropy + DICE loss\n",
    "def comb_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    o = tf.nn.sigmoid_cross_entropy_with_logits(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)\n",
    "\n",
    "\n",
    "def balanced_cross_entropy(y_true, y_pred):\n",
    "    weight_a = beta * tf.cast(y_true, tf.float32)\n",
    "    weight_b = (1 - beta) * tf.cast(1 - y_true, tf.float32)\n",
    "    \n",
    "    o = (tf.math.log1p(tf.exp(-tf.abs(y_pred))) + tf.nn.relu(-y_pred)) * (weight_a + weight_b) + y_pred * weight_b\n",
    "    return tf.reduce_mean(o)\n",
    "\n",
    "beta = 0.7\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = y_true * y_pred\n",
    "    denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)\n",
    "\n",
    "    return 1 - tf.reduce_sum(numerator) / tf.reduce_sum(denominator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NApT8Bd36gaG"
   },
   "outputs": [],
   "source": [
    "weight_path=\"/content/drive/MyDrive/Диплом/Ship_detection/weights/u_net/{}_weights.best.hdf5\".format('seg_model_TSKY_BETA_0-7_RMS')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=1, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2,\n",
    "                      patience=20) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG_5sqh9nVvw",
    "outputId": "82a3d734-bd36-4f3f-d6ef-0e26a463eb13"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8uBFioZa5O-"
   },
   "outputs": [],
   "source": [
    "RMS = RMSprop( learning_rate=0.001,\n",
    "                    rho=0.9,\n",
    "                    momentum=0.0,\n",
    "                    epsilon=1e-07,\n",
    "                    centered=False,\n",
    "                    name=\"RMSprop\")\n",
    "    \n",
    "adam = Adam(learning_rate=0.001,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-07,\n",
    "                amsgrad=False,\n",
    "                name=\"Adam\")\n",
    "seg_model.compile(optimizer = adam, loss= tversky_loss, metrics=['binary_accuracy',  dice_coef, true_positive_rate, tf.keras.metrics.FalsePositives()])\n",
    "#weight_path1=\"/content/drive/MyDrive/Диплом/Ship_detection/weights/u_net/{}_weights.best.hdf5\".format('seg_model')\n",
    "#seg_model.load_weights(weight_path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AAOcABo6j61",
    "outputId": "897470e6-0868-437a-b9b1-3fbfb9643d67"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit(seq_model):    \n",
    "    step_count = MAX_TRAIN_STEPS\n",
    "    #step_count = train_df.shape[0]//BATCH_SIZE\n",
    "    aug_gen = create_aug_gen(make_image_gen(train_df))\n",
    "    loss_history = [seg_model.fit(aug_gen, \n",
    "                                 steps_per_epoch=step_count,\n",
    "                                # batch_size = BATCH_SIZE,\n",
    "                                 epochs=MAX_TRAIN_EPOCHS,\n",
    "                                 validation_data=(valid_x, valid_y),\n",
    "                                 callbacks=callbacks_list\n",
    "                                )]\n",
    "    return loss_history\n",
    "\n",
    "loss_history = fit(seg_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "buDv8vu-6sGC",
    "outputId": "76170207-74d9-4505-b54b-c57dc77e6773"
   },
   "outputs": [],
   "source": [
    "def show_loss(loss_history):\n",
    "    epochs = np.concatenate([mh.epoch for mh in loss_history])\n",
    "    fig, (ax1, ax2, ax3, ax, ax5) = plt.subplots(1, 5, figsize=(22, 10))\n",
    "    \n",
    "    _ = ax1.plot(epochs, np.concatenate([mh.history['loss'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "    \n",
    "    _ = ax2.plot(epochs, np.concatenate([mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_binary_accuracy'] for mh in loss_history]), 'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('Binary Accuracy (%)')\n",
    "\n",
    "    _ = ax3.plot(epochs, np.concatenate([mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_dice_coef'] for mh in loss_history]), 'r-')\n",
    "    ax3.legend(['Training', 'Validation'])\n",
    "    ax3.set_title('DICE Coefficient (%)')\n",
    "\n",
    "    _ = ax4.plot(epochs, np.concatenate([mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_true_positive_rate'] for mh in loss_history]), 'r-')\n",
    "    ax4.legend(['Training', 'Validation'])\n",
    "    ax4.set_title('TFP')\n",
    "\n",
    "      _ = ax5.plot(epochs, np.concatenate([mh.history['false_positives'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_false_positives'] for mh in loss_history]), 'r-')\n",
    "    ax5.legend(['Training', 'Validation'])\n",
    "    ax5.set_title('FPR')\n",
    "\n",
    "\n",
    "    fig.savefig('/content/drive/MyDrive/Диплом/Ship_detection/RMS_TSKY_BETA_0-3_hist.png')\n",
    "\n",
    "show_loss(loss_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D9vDpCwEncfl"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "r5XFA_lE6urX"
   },
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('/content/drive/MyDrive/Диплом/Ship_detection/weights/u_net/seg_TSKY_BETA_0-7_RMSmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zohjgmPFMBu9"
   },
   "outputs": [],
   "source": [
    "pred_y = seg_model.predict(valid_x)\n",
    "print(pred_y.shape, pred_y.min(axis=0).max(), pred_y.max(axis=0).min(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZamIqVQD6w3r"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 20))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt6wLaXqK6at"
   },
   "source": [
    "## Подготовка для полноразмерной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bLlCMaX0LBW1"
   },
   "outputs": [],
   "source": [
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save('/content/drive/MyDrive/Диплом/Ship_detection/weights/u_net/fullres_TSKY_BETA_0-7_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0H7YfR5Fnefl"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbB0kb6761xx"
   },
   "source": [
    "## Визуализируем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YJ8zSMoB60di"
   },
   "outputs": [],
   "source": [
    "def raw_prediction(img, path=train_image_dir):\n",
    "    c_img = imread(os.path.join(path, c_img_name))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    return cur_seg, c_img[0]\n",
    "\n",
    "def smooth(cur_seg):\n",
    "    return binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n",
    "\n",
    "def predict(img, path=train_image_dir):\n",
    "    cur_seg, c_img = raw_prediction(img, path=path)\n",
    "    return smooth(cur_seg), c_img\n",
    "\n",
    "\n",
    "## Get a sample of each group of ship count\n",
    "n_samples = 100\n",
    "samples = valid_df.groupby('ships').apply(lambda x: x.sample(random_state = SEED, n_samples))\n",
    "fig, m_axs = plt.subplots(samples.shape[0], 4, figsize = (15, samples.shape[0]*4))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2, ax3, ax4), c_img_name in zip(m_axs, samples.ImageId.values):\n",
    "    first_seg, first_img = raw_prediction(c_img_name, train_image_dir)\n",
    "    ax1.imshow(first_img)\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(first_seg[:, :, 0], cmap=get_cmap('jet'))\n",
    "    ax2.set_title('Model Prediction')\n",
    "    reencoded = masks_as_color(multi_rle_encode(smooth(first_seg)[:, :, 0]))\n",
    "    ax3.imshow(reencoded)\n",
    "    ax3.set_title('Prediction Masks')\n",
    "    ground_truth = masks_as_color(masks.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels'])\n",
    "    ax4.imshow(ground_truth)\n",
    "    ax4.set_title('Ground Truth')\n",
    "    \n",
    "fig.savefig('/content/drive/MyDrive/Диплом/Ship_detection/RMS_50_TSKY_BETA_0-7_.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VfPD4c_rMHPE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-net_Test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
