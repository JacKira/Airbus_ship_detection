{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHR_WvGlIOpV"
   },
   "source": [
    "# Оптимизация RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Tcrkx0pftc6",
    "outputId": "356f1063-61ec-4a28-93a1-8be6dd566472",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C10OSwcxiUeR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2bp9N8siUem",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evo-WrjpiUen",
    "outputId": "db7e0140-8739-4cf7-a3d3-4c2a7918dd00",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzYZSZ9RiUen",
    "outputId": "d1b96feb-9dbc-4c31-8f8f-42d4b0d7976a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eod1bNV7iUeo",
    "outputId": "ba58f3bf-a406-45b3-c519-40f4a329c131",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WRXHQYEiUeo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiuA9TgqiUeo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HycXEiQslgy6",
    "outputId": "0db58df4-ef32-4ffd-e57d-fa733f707cee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2HQdQIddiUep",
    "outputId": "32d6032e-07f6-4be8-c245-b55a9bd9b7df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 64))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 64))) #4\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 128))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 128))) #7\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #8\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 256))) #11\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #12\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #15\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #16\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Wf2fBwuiUep",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop\n",
    "epochs = 50\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPfrfAlfiUeq",
    "outputId": "6c2bc10b-e338-4db1-9848-268b84a0129a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_J5fX9yAYsQ",
    "outputId": "b4332236-0b49-4ba5-8352-cb1695c91b95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98rylr03iUeq",
    "outputId": "2de8a388-b844-4069-a3b7-36705a090585",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lXdz6i0UiUer",
    "outputId": "ba08d8ac-4c99-46d4-c2f4-d5ae242cf47b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmjr0S8ZiUer",
    "outputId": "104b2d00-363b-49b0-c044-bb79c1b8cca7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VB30VzzyiUer",
    "outputId": "2b0d2d29-0c8a-4045-8db4-81af53a4a198",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/CURSE_RES/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORqLKEM5iUer",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6YkGnmlH3cz"
   },
   "source": [
    "# Гипотеза о применении оптимизатора ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "vvtjZ_-DH83Y",
    "outputId": "6179fc80-3566-4101-a11e-e1c26e7800af",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9WVyCSIH83Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2X5zDMVH83Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wY2hivCYH83a",
    "outputId": "c003e333-8638-4720-a850-2ca8c34bc590",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZujdndtfH83b",
    "outputId": "0d9682d7-64c4-46df-aa07-a5d019ab04c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7WqKo3gH83c",
    "outputId": "9b02304e-bab8-4d70-92f2-41c6843948a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsREI0lOH83c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FEHgy52H83d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryWwfEdcH83e",
    "outputId": "ac294747-6883-407c-cc17-2070475cc965",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S-S2R8AbH83e",
    "outputId": "b972961a-afe6-40a4-ecf5-e24164d41c20",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 64))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 64))) #4\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 128))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 128))) #7\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #8\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 256))) #11\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #12\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #15\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #16\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSdoUoigH83g",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 50\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "#optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AlM2ei8H83g",
    "outputId": "a225a91a-4297-48c7-b53f-5830d4b0aead",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNFSgiYtH83g",
    "outputId": "03dc3141-037a-4694-fbf3-565bdfe2ee9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4z_7QsleH83h",
    "outputId": "5d1225db-3e9f-4477-8591-66dac5a2fb70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zyZnk8wyH83h",
    "outputId": "de5e9c2e-07df-4559-bb35-a964a73a3bc9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_2'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc_2'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_3'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_3'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orXZ1y_2H83h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtFwMqlcH83i",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/ADAM_res/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_2'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc_2'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuW_DWVgiUes",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP2f1mhj3aRd"
   },
   "source": [
    "# ADAM с иной функцией потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtDZZCkp3gAQ",
    "outputId": "bd13282f-1c05-4f7a-ebfa-f602d0455693",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8o4SGpq53gAR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUtGtQM83gAR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yJM1Ug53gAS",
    "outputId": "a93d5f55-d4b1-4c20-ccf0-54b6fca54973",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jn6LXeQ3gAT",
    "outputId": "618de965-226f-4499-8cff-58b7117d49d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXDK_CS73gAU",
    "outputId": "84a8a6ad-070b-4608-a9b9-6eac13c068df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMeBdExU3gAV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDVP7PU53gAW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoDZNFrZ3gAX",
    "outputId": "bb033e39-1b68-4014-fc9f-66fb9af98795",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XoUCHdCT3gAY",
    "outputId": "25982ccd-5e2d-4987-8d9e-477c9774dab4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128, 128, 64))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 64))) #4\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, 128))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 128))) #7\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #8\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, 256))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 256))) #11\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #12\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, 512))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #15\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #16\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, 512))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuSnxO3R3gAZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 50\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "#optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQdFDmhF3gAZ",
    "outputId": "feb9a3cb-b8ce-49e6-c6d3-7effb62accd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_llxn9Rt3gAZ",
    "outputId": "f3685a49-24b9-4745-b4d6-9c1c8ddb4819",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qYSVQ6y3gAa",
    "outputId": "6772cd2f-3a29-4d08-837a-ca99fa052471",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H5S_vImP3gAa",
    "outputId": "c5803be6-8509-465b-a469-abd4c96492bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlvySNis3gAb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "22iFQvjp3gAb",
    "outputId": "529a5888-0004-4dcc-9656-64b2fa63deef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/ADAM_res2/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwKDfGc83gAc",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRJcGGnGINO6"
   },
   "source": [
    "# RMSProp с иной функцией потерь и увеличением ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kW7--JwINO_",
    "outputId": "3669c8c0-9945-45a9-a046-fc4d9e955730",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP_TETTSINPC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBoDpNV8INPC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5loBfLOINPD",
    "outputId": "fa2bbffb-8206-42cc-84ae-b728d0ba134f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xqxuk1N2INPD",
    "outputId": "34c6f0e6-9b4c-43d7-c4ff-0c7cbcf0e9c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZ9GvnryINPE",
    "outputId": "3bed0dbe-dc5a-49b3-be69-1fb8240bee8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqriRt_SINPF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAbycypVINPH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s0xJmITINPI",
    "outputId": "3a93d805-c1d6-4adc-9632-d23045e73184",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cymW82rkINPI",
    "outputId": "46544a92-7961-4144-c1b7-6ff960a49be1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "base_filter_count = 64\n",
    "kernel = (5, 5)\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, base_filter_count))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count))) #4\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count * 2))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 2))) #7\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #8\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 4))) #11\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #12\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #15\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #16\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vyMS01xliG5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 50\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "#optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPEVJQEYINPL",
    "outputId": "272e9efb-0e34-40a4-bfbe-01c5268e39b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpKMlcwFINPL",
    "outputId": "87679912-c61f-42db-d834-a65f833ff942",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omXcYEOoINPM",
    "outputId": "795d4c75-eaf7-4e6e-c156-47737ebe7940",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CHVh6qJVINPN",
    "outputId": "ff732507-ce07-4c11-edc2-783d0f1b2a66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RehmuTLSINPN",
    "outputId": "bcdefaa3-cc87-4b97-dc47-5bda7106c9fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nh7QXF5AINPO",
    "outputId": "eaaa69e2-fcab-4d90-b627-326a157a4a95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/RMS_bin/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbHtKqM1INPO",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SraV_lMORfA-",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCuGddFDRf_V"
   },
   "source": [
    "# RMSProp с иной функцией потерь и уменьшением ядра свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AvQKNGaRf_Y",
    "outputId": "cc67efa8-44e8-4878-9722-d763146c2b45",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B39KVTqcRf_b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBSx2nnHRf_c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWfBigI3Rf_d",
    "outputId": "76d93bb2-5aee-4170-ed6b-835e6cecbd8c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHYFPzvJRf_d",
    "outputId": "5eb8aef5-a67f-4005-c28c-8a5f2cea4956",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BUlxSSURf_e",
    "outputId": "12d86b12-f835-4de6-abb5-81b88a57af0f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-30vQnWuRf_f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WE2cErshRf_h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk3UG0BDRf_h",
    "outputId": "a6579e87-b718-4659-e295-be20c2f8603e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-zl7QVD3Rf_i",
    "outputId": "db8901e2-0463-4cd3-e292-7912d0acf0e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "base_filter_count = 64\n",
    "kernel = (2, 2)\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, base_filter_count))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count))) #4\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count * 2))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 2))) #7\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #8\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 4))) #11\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #12\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #15\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #16\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvM2TsDaRf_j",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 50\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "#optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "569tSj1DRf_k",
    "outputId": "97d7b67e-f6c8-4d13-8009-c5e1e33ed2ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hh6-lqXDRf_k",
    "outputId": "27d3916a-615b-40fc-c55d-487e3d1941b5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXSOc7chRf_l",
    "outputId": "79560818-48d0-4107-f2a9-5705bce83c0e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "krceOkY1Rf_l",
    "outputId": "3e4f823d-d581-4216-f5c9-199bbfc4d131",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaSXlYUaRf_m",
    "outputId": "8c48d142-ccf2-4235-d2b8-b45d407a474b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KAcs5WJBRf_n",
    "outputId": "cdcc53e4-b633-4d88-f03b-7369a97fc9a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/RMS_bin_kernel_2_2/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kU-fx48wRf_n",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leOD7R6UrFEb"
   },
   "source": [
    "# RMSProp с иной функцией потерь и уменьшением ядра свертки, обучение 100 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHcOo3TSrFEc",
    "outputId": "91eacd61-f968-4b8a-dd18-c97354388ef7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKp48XFrrFEd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_l73VQVrFEe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UevU_rZBrFEf",
    "outputId": "8af865b4-8042-4dcb-ab82-850c4e1bcaef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsdydWK8rFEg",
    "outputId": "dc368470-2500-4f8f-d4ca-f47cc16d0416",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSIFKO6arFEh",
    "outputId": "37f8a0e3-c084-414f-e75b-508b45058d49",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q6uUxrcrFEj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDBwiuqerFEj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kF9Zd2PTrFEl",
    "outputId": "2272d66e-cdd4-4655-b8fd-57e999af02cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ewbo77d9rFEl",
    "outputId": "33206147-605c-4507-ed57-066fd938f729",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "base_filter_count = 64\n",
    "kernel = (2, 2)\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, base_filter_count))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count))) #4\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count * 2))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 2))) #7\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #8\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 4))) #11\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #12\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #15\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #16\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnM92YJYrFEn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 100\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "#optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NL6lgTRrFEo",
    "outputId": "ccaa002f-3b13-4a05-857d-d9a63f7a4b44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lSX8DxYrFEp",
    "outputId": "333bb129-18f2-484b-a489-73d00027c612",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQN-sC1QrFEp",
    "outputId": "85f025b5-ee53-4bc1-b9f3-d0a7898fd791",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ccycvBCtrFEq",
    "outputId": "976bee71-0e03-415c-cad2-0b99e5c9d5a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fkZ0YBgrFEq",
    "outputId": "cf322b2c-a928-466a-dc2e-311a5c198d1e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oRzWF0lNrFEs",
    "outputId": "fd6bd184-f37f-4473-f715-07e73dc6fb44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/RMS_bin_kernel_2_2_50epc/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2rpCPbRrFEt",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bOJxAYDJVk"
   },
   "source": [
    "# RMSProp с иной функцией потерь и уменьшением ядра свертки, обучение 1000 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pM9aLfbWDJVo",
    "outputId": "ee61e934-d313-43c4-8947-64e8eb2ec4f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVu8ZZ15DJVq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzQxwlwlDJVr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YiB4S-vDJVs",
    "outputId": "36df495c-087b-4761-97e2-fba7c3c00292",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ze0oBjVDJVs",
    "outputId": "2da1e8fb-c09d-4ee2-812f-a7f8fddc268a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGFs_GsGDJVu",
    "outputId": "1ebd6878-8038-483f-8933-536cdede71c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split Training data to training data and validate data to detect overfit\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2, random_state = SEED)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyK_vhPEDJVv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data augumatation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgPAempJDJVw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load ResNet50 model with Keras\n",
    "#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "#from keras.applications.resnet50 import ResNet50 as ResModel\n",
    "#from keras.applications.vgg16 import VGG16 as VGG16Model\n",
    "#img_width, img_height = 256, 256\n",
    "#model = VGG16Model(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YObYnvlpDJVx",
    "outputId": "e1fae449-4b3d-4272-bda8-59761d7bb696",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1x3kI96pDJVx",
    "outputId": "06a56acd-78d7-44f2-cf56-6560db083b66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On this case, we only need predict 2 category (1. have ship, 2. no ship)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "base_filter_count = 64\n",
    "kernel = (2, 2)\n",
    "# creating the final model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, 3))) #1\n",
    "model.add(Conv2D(filters = base_filter_count, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128, 128, base_filter_count))) #2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                  #3\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count))) #4\n",
    "model.add(Conv2D(filters = base_filter_count * 2, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (128/2, 128/2, base_filter_count * 2))) #5\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                       #6\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 2))) #7\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #8\n",
    "model.add(Conv2D(filters = base_filter_count * 4, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (64/2, 64/2, base_filter_count * 4))) #9\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #10\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 4))) #11\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #12\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (32/2, 32/2, base_filter_count * 8))) #13\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                   #14\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #15\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #16\n",
    "model.add(Conv2D(filters = base_filter_count * 8, kernel_size = kernel, padding = 'Same', activation ='relu', input_shape = (16/2, 16/2, base_filter_count * 8))) #17\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))                                                                                    #18\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "image_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file = image_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irO_sxdjDJV0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #Set Hyperparameter and Start training\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "epochs = 1000\n",
    "lrate = 0.001 #learning rate\n",
    "batch_size = 256\n",
    "decay = lrate/epochs # Learning rate decay over each update\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = decay)\n",
    "#optimizer = Adam(learning_rate = 0.001, epsilon = 1e-08, decay = decay)\n",
    "#model.load_weights(\"transfer_ship_v1_5.h5\")\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'ROC'), tf.keras.metrics.AUC(curve = 'PR')])\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8V1NJsNDJV0",
    "outputId": "460b2695-2e9c-4f4a-ee89-fb664f85a257",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5EwjccoDJV1",
    "outputId": "358ba81d-8727-46d0-f4ac-9ab10fc6fcbc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pPsnPF-DJV1",
    "outputId": "e6ed6209-0fa6-456b-b358-6127b442601e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(img_gen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, validation_data = (x_val,y_val),\n",
    "                          steps_per_epoch = int(len(x_train)/batch_size), callbacks=callbacks_list)\n",
    "model.save('transfer_ship_exp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9880uP2HDJV2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5DTDM1ADJV2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lklXsAiDJV3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_path = \"/content/drive/MyDrive/Диплом/Ship_detection/CNN_PRACT/PLOTS/RMS_bin_kernel_2_2_1000epc/\"\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(plot_path + \"loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc'], color='b', label=\"Training ROC\")\n",
    "plt.plot(history.history['val_auc'], color='r',label=\"Validation ROC\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"roc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auc_1'], color='b', label=\"Training PR\")\n",
    "plt.plot(history.history['val_auc_1'], color='r',label=\"Validation PR\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(plot_path + \"pr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxvZpq8gDJV4",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JWU4-uxgYce"
   },
   "source": [
    "# Базовое решение - подбрасывание монеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qgd2z3xget_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "import random\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OS7JeRgWgeuA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/data_for_train.npy')\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEBHb21jgeuA",
    "outputId": "42eac386-87c8-44a5-9784-10875402dc52",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"array sizes of data array: \", data.shape)\n",
    "print(\"array sizes of target array: \",data_target.shape)\n",
    "print(\"example of one image in data array\\n\", data[0])  \n",
    "print(\"example of target for one image in array: \", data_target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQxGBdXLgeuC",
    "outputId": "c5e36d50-30d9-42e3-bcc9-ed2e2e0434cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qhn2SVSrgiFu",
    "outputId": "77788d87-398a-48dd-d3fc-f9950f19659b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(targets)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcILS3s5goce",
    "outputId": "7e0913af-8f86-4f37-b76f-20f96ce124b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = np.array([[0] * 2] * n)\n",
    "for i in range(n):\n",
    "    rnd = random.random()\n",
    "    Y[i] = [round(1 - rnd), round(rnd)]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm7QVzLXgzdf",
    "outputId": "4709481f-b788-4bec-be81-395e9ff18ca0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Точность (accuracy) равно \", accuracy_score(targets, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oGLD3CzhrMQ",
    "outputId": "cbfe682f-f53e-4036-b2bb-7f1db17c6258",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(\"Точность (precision) равно \", \n",
    "      precision_score(targets.reshape(-1, 1), Y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwTkYO7dnvrI",
    "outputId": "24f53ed6-40e7-4dbe-dfd8-22f8a3333938",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(\"Полнота (recall) равно \",\n",
    "      recall_score(targets.reshape(-1, 1), Y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUH6eGQCoQe_",
    "outputId": "07fd9bb1-8f7a-42dd-8664-13ec589f294e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import metrics\n",
    "pr, rc, tr = precision_recall_curve(targets.reshape(-1, 1), np.array([1/2, 1/2] * n).reshape(-1, 1))\n",
    "metrics.auc(pr, rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kzb9HjMgq2ey",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxdcHlDPx8ub"
   },
   "source": [
    "# Решение задачи человеком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlKzjRWyzu80",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from PIL import Image\n",
    "import random\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oltkLfvU0iFS",
    "outputId": "4224e49e-c58c-4d79-bb5b-6dc0f2aef7b5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Диплом/Ship_detection/Input/ImgForTest.csv', index_col= 0)\n",
    "data_target = np.load('/content/drive/MyDrive/Диплом/Ship_detection/Input/target_for_train.npy')\n",
    "#Set target to one hot target for classification problem\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "targets = data_target.reshape(len(data_target),-1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(targets)\n",
    "targets = enc.transform(targets).toarray()\n",
    "print(targets.shape)\n",
    "del data_target\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3DuSmTqd0vAT",
    "outputId": "943231af-e4ec-4bab-94f7-2c9661655127",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NvbII9P0MuQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train_path = '/content/drive/MyDrive/Диплом/Ship_detection/Input/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZA1R5VV7yHQK",
    "outputId": "01ddf54a-071b-4009-e438-71ea43913fc0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "index = 0\n",
    "n = 100\n",
    "Y = np.array([[0] * 2] * n)\n",
    "Y_true = np.array([[0] * 2] * n)\n",
    "l = data['ImageId'].values\n",
    "anss = data['exist_ship'].values\n",
    "offset = 500\n",
    "for i in range(n): \n",
    "    image_name = l[offset + i]\n",
    "    imageA = Image.open(Train_path+image_name).resize((256, 256)) #open and resize image\n",
    "    display(imageA)\n",
    "    ans = int(input())\n",
    "    Y[i][ans] = 1\n",
    "    Y_true[i][anss[offset + i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIsxWDan1hkv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('/content/drive/MyDrive/Диплом/Ship_detection/Input/human_ans', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZyFvRLl7B7E",
    "outputId": "3ac39fc6-5e77-4502-bbb2-8e2f41b8b29b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Точность (accuracy) равно \", accuracy_score(Y_true, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKuht6lR7B7H",
    "outputId": "9a8f5b3a-e6e4-4ada-97d5-83f2fd7ee0cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(\"Точность (precision) равно \", \n",
    "      precision_score(Y_true.reshape(-1, 1), Y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXruu5yY7B7I",
    "outputId": "26caf7ed-3795-4e94-a5e2-c17ef51a5c83",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(\"Полнота (recall) равно \",\n",
    "      recall_score(Y_true.reshape(-1, 1), Y.reshape(-1, 1)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CHR_WvGlIOpV",
    "m6YkGnmlH3cz",
    "OP2f1mhj3aRd"
   ],
   "machine_shape": "hm",
   "name": "CNN_for_pract.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
